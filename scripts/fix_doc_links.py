#!/usr/bin/env python3
"""
Documentation link fixer - applies mechanical fixes from fix plan.

Reads fix plan JSON generated by check_doc_links.py and applies fixes
based on confidence thresholds and policy-driven resolution.

Modes:
- Dry-run (default): Preview fixes without applying
- Execute: Apply fixes with atomic backup

Safety features:
- Backup before applying (archive/diagnostics/doc_link_fix_backup_{timestamp}.zip)
- Confidence-based auto-apply (high only by default, --apply-medium flag)
- Re-validation after fixes (confirm 0 broken links)
"""

from __future__ import annotations

import argparse
import json
import re
import sys
import zipfile
from datetime import datetime
from pathlib import Path
from typing import Dict, List


def _configure_utf8_stdio() -> None:
    """
    Make CLI output resilient on Windows terminals that default to legacy encodings (e.g. cp1252).

    This script prints Unicode symbols (‚ö†Ô∏è/‚úÖ/‚ùå). On some Windows shells, that can raise
    UnicodeEncodeError and crash the fixer. Prefer UTF-8 with replacement.
    """
    for stream in (sys.stdout, sys.stderr):
        try:
            if hasattr(stream, "reconfigure"):
                stream.reconfigure(encoding="utf-8", errors="replace")
        except Exception:
            pass


def create_backup(repo_root: Path, files_to_backup: List[Path]) -> Path:
    """
    Create atomic backup of files before applying fixes.

    Args:
        repo_root: Repository root
        files_to_backup: List of file paths to backup

    Returns:
        Path to backup zip file
    """
    timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
    backup_path = repo_root / "archive" / "diagnostics" / f"doc_link_fix_backup_{timestamp}.zip"
    backup_path.parent.mkdir(parents=True, exist_ok=True)

    with zipfile.ZipFile(backup_path, 'w', zipfile.ZIP_DEFLATED) as zf:
        for file_path in files_to_backup:
            if file_path.exists():
                arcname = file_path.relative_to(repo_root)
                zf.write(file_path, arcname=str(arcname))

    return backup_path


def load_fix_plan(plan_path: Path) -> Dict:
    """
    Load fix plan JSON.

    Args:
        plan_path: Path to fix plan JSON file

    Returns:
        Fix plan dictionary
    """
    if not plan_path.exists():
        raise FileNotFoundError(f"Fix plan not found: {plan_path}")

    content = plan_path.read_text(encoding='utf-8')
    return json.loads(content)


def apply_fix_to_line(line: str, broken_target: str, suggested_fix: str) -> str:
    """
    Apply fix to a single line by replacing the broken target.

    Handles both markdown links [text](target) and backtick paths `target`.

    Args:
        line: Source line
        broken_target: Broken link target to replace
        suggested_fix: Suggested replacement target

    Returns:
        Fixed line
    """
    # Escape special regex characters in targets
    escaped_broken = re.escape(broken_target)

    # Normalize suggested fix to forward slashes (markdown standard)
    normalized_fix = suggested_fix.replace('\\', '/')

    # Try markdown link pattern: [text](broken_target)
    markdown_pattern = r'\[([^\]]+)\]\(' + escaped_broken + r'([#\)])'
    if re.search(markdown_pattern, line):
        # Use a replacement function to avoid regex escape issues
        def markdown_repl(match):
            return f'[{match.group(1)}]({normalized_fix}{match.group(2)}'
        return re.sub(markdown_pattern, markdown_repl, line)

    # Try backtick pattern: `broken_target`
    backtick_pattern = r'`' + escaped_broken + r'`'
    if re.search(backtick_pattern, line):
        def backtick_repl(match):
            return f'`{normalized_fix}`'
        return re.sub(backtick_pattern, backtick_repl, line)

    # Direct replacement as fallback
    return line.replace(broken_target, normalized_fix)


def apply_fixes(
    repo_root: Path,
    fix_plan: Dict,
    dry_run: bool = True,
    apply_medium: bool = False,
    force: bool = False
) -> Dict:
    """
    Apply fixes from fix plan.

    Args:
        repo_root: Repository root
        fix_plan: Fix plan dictionary
        dry_run: If True, preview fixes without applying
        apply_medium: If True, apply medium confidence fixes
        force: If True, apply all fixes regardless of confidence

    Returns:
        Dict with fix statistics
    """
    broken_links = fix_plan.get('broken_links', [])

    # Group fixes by source file and line number
    fixes_by_file = {}
    for broken in broken_links:
        # Skip if no suggested fix
        if not broken.get('suggested_fix'):
            continue

        # Skip based on confidence threshold
        confidence = broken.get('confidence', 'low')
        if not force:
            if confidence == 'low':
                continue
            if confidence == 'medium' and not apply_medium:
                continue

        source_file = broken['source_file']
        if source_file not in fixes_by_file:
            fixes_by_file[source_file] = []

        fixes_by_file[source_file].append(broken)

    # Statistics
    stats = {
        'files_modified': 0,
        'links_fixed': 0,
        'skipped': 0,
        'errors': 0
    }

    # Preview or apply fixes
    for source_file_rel, fixes in sorted(fixes_by_file.items()):
        source_file = repo_root / source_file_rel

        if not source_file.exists():
            print(f"‚ö†Ô∏è  File not found: {source_file_rel}")
            stats['errors'] += 1
            continue

        # Read file
        content = source_file.read_text(encoding='utf-8')
        lines = content.split('\n')

        # Apply fixes (in reverse line order to preserve line numbers)
        modified = False
        for fix in sorted(fixes, key=lambda f: f['line_number'], reverse=True):
            line_num = fix['line_number']
            broken_target = fix['broken_target']
            suggested_fix = fix['suggested_fix']
            confidence = fix['confidence']

            # Validate line number
            if line_num < 1 or line_num > len(lines):
                print(f"‚ö†Ô∏è  Invalid line number {line_num} in {source_file_rel}")
                stats['errors'] += 1
                continue

            # Apply fix to line
            original_line = lines[line_num - 1]
            fixed_line = apply_fix_to_line(original_line, broken_target, suggested_fix)

            if fixed_line != original_line:
                if dry_run:
                    print(f"üìù {source_file_rel}:{line_num} [{confidence}]")
                    print(f"   - {broken_target}")
                    print(f"   + {suggested_fix}")
                else:
                    lines[line_num - 1] = fixed_line

                modified = True
                stats['links_fixed'] += 1
            else:
                print(f"‚ö†Ô∏è  No change detected for line {line_num} in {source_file_rel}")
                stats['skipped'] += 1

        # Write back if modified and not dry-run
        if modified and not dry_run:
            fixed_content = '\n'.join(lines)
            source_file.write_text(fixed_content, encoding='utf-8')
            stats['files_modified'] += 1
            print(f"‚úÖ Fixed {source_file_rel}")

    return stats


def main():
    _configure_utf8_stdio()
    parser = argparse.ArgumentParser(
        description="Apply mechanical fixes for broken documentation links"
    )
    parser.add_argument(
        "--repo-root",
        type=Path,
        default=Path(__file__).parent.parent,
        help="Repository root directory (default: autodetect)"
    )
    parser.add_argument(
        "--fix-plan",
        type=Path,
        default=None,
        help="Path to fix plan JSON (default: archive/diagnostics/doc_link_fix_plan.json)"
    )
    parser.add_argument(
        "--execute",
        action="store_true",
        help="Apply fixes (default: dry-run preview)"
    )
    parser.add_argument(
        "--apply-medium",
        action="store_true",
        help="Apply medium confidence fixes in addition to high"
    )
    parser.add_argument(
        "--force",
        action="store_true",
        help="Apply all fixes regardless of confidence (dangerous)"
    )
    parser.add_argument(
        "--no-backup",
        action="store_true",
        help="Skip backup creation (dangerous, not recommended)"
    )

    args = parser.parse_args()
    repo_root = args.repo_root.resolve()

    # Load fix plan
    plan_path = args.fix_plan or (repo_root / "archive" / "diagnostics" / "doc_link_fix_plan.json")
    if not plan_path.is_absolute():
        plan_path = repo_root / plan_path

    print("=" * 70)
    print("DOCUMENTATION LINK FIXER")
    print("=" * 70)
    print(f"Repository root: {repo_root}")
    print(f"Fix plan: {plan_path.relative_to(repo_root) if plan_path.is_relative_to(repo_root) else plan_path}")
    print(f"Mode: {'EXECUTE' if args.execute else 'DRY-RUN'}")
    print(f"Confidence threshold: {'all' if args.force else ('medium+high' if args.apply_medium else 'high only')}")
    print("=" * 70)
    print()

    # Load fix plan
    try:
        fix_plan = load_fix_plan(plan_path)
    except FileNotFoundError as e:
        print(f"‚ùå {e}")
        print()
        print("Generate fix plan first:")
        print("  python scripts/check_doc_links.py --export-json")
        return 1

    summary = fix_plan.get('summary', {})
    print("Fix plan summary:")
    print(f"  Total broken links: {summary.get('total_broken', 0)}")
    print(f"  Auto-fixable (high): {summary.get('by_confidence', {}).get('high', 0)}")
    print(f"  Auto-fixable (medium): {summary.get('by_confidence', {}).get('medium', 0)}")
    print(f"  Manual review: {summary.get('by_confidence', {}).get('low', 0)}")
    print()

    # Create backup if executing and not disabled
    if args.execute and not args.no_backup:
        broken_links = fix_plan.get('broken_links', [])
        files_to_backup = set()
        for broken in broken_links:
            source_file = repo_root / broken['source_file']
            if source_file.exists():
                files_to_backup.add(source_file)

        if files_to_backup:
            print(f"Creating backup of {len(files_to_backup)} files...")
            backup_path = create_backup(repo_root, list(files_to_backup))
            try:
                rel_backup = backup_path.relative_to(repo_root)
                print(f"‚úÖ Backup created: {rel_backup}")
            except ValueError:
                print(f"‚úÖ Backup created: {backup_path}")
            print()

    # Apply fixes
    stats = apply_fixes(
        repo_root,
        fix_plan,
        dry_run=not args.execute,
        apply_medium=args.apply_medium,
        force=args.force
    )

    # Summary
    print()
    print("=" * 70)
    print("SUMMARY")
    print("=" * 70)
    print(f"Files modified: {stats['files_modified']}")
    print(f"Links fixed: {stats['links_fixed']}")
    print(f"Skipped: {stats['skipped']}")
    print(f"Errors: {stats['errors']}")

    if not args.execute:
        print()
        print("‚ÑπÔ∏è  This was a dry-run. Add --execute to apply fixes.")
        print("   Example: python scripts/fix_doc_links.py --execute")
    else:
        print()
        print("‚úÖ Fixes applied. Re-run check_doc_links.py to validate.")

    return 0


if __name__ == "__main__":
    sys.exit(main())
