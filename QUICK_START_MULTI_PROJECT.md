# Quick Start: Multi-Project Setup

## âœ… **Multi-Project Isolation is NOW SUPPORTED!**

You can now build multiple isolated projects with Autopack. Each project has its own:
- âœ… Directory (outside of Autopack)
- âœ… Git repository
- âœ… `.autonomous_runs/` tracking
- âœ… Source code

---

## **Simple Usage**

### **Build a Single Project:**

```python
from integrations.supervisor import Supervisor

# Point Autopack at your project
supervisor = Supervisor(
    target_repo_path="c:\\Projects\\my-web-app"  # â† Your project directory
)

# Define your build plan
tiers = [...]
phases = [...]

# Run autonomous build
result = supervisor.run_autonomous_build(
    run_id="my-app-v1",
    tiers=tiers,
    phases=phases
)
```

**That's it!** Autopack will:
1. Build code in `c:\\Projects\\my-web-app`
2. Create `.autonomous_runs/` there
3. Apply patches to that repository
4. Track everything isolated from other projects

---

## **Quick Example: Try It Now!**

### **Step 1: Run the Multi-Project Example**

```bash
# Make sure Docker is running
docker-compose up -d

# Run the example
python examples/multi_project_example.py
```

### **Step 2: Choose a Project**

The script will ask:
```
Which project to build? (1=web-service, 2=data-pipeline, 3=both):
```

Choose `1` to build a FastAPI web service.

### **Step 3: Watch It Build**

You'll see:
```
[Supervisor] Target repository: c:\Projects\web-service
[Supervisor] Creating run: web-service-v1
[Supervisor] âœ… Run created
[Supervisor] ğŸ§  Model Selection: gpt-4o-mini
[Supervisor] â†’ Dispatching to Builder...
[Supervisor] âœ… Builder completed
[Supervisor] â†’ Dispatching to Auditor...
[Supervisor] âœ… Phase approved
```

### **Step 4: Check Your Project**

```bash
cd c:\Projects\web-service
ls

# You'll see:
# - main.py (generated by Builder!)
# - .autonomous_runs/ (tracking files)
# - .git/ (git repository)
# - README.md
```

---

## **Directory Structure**

```
c:\Projects\                    # Your projects (outside Autopack)
â”œâ”€â”€ web-service\
â”‚   â”œâ”€â”€ .git\
â”‚   â”œâ”€â”€ .autonomous_runs\       # Run tracking for this project
â”‚   â”‚   â””â”€â”€ web-service-v1\
â”‚   â”œâ”€â”€ main.py                 # Generated code
â”‚   â””â”€â”€ README.md
â”‚
â”œâ”€â”€ data-pipeline\
â”‚   â”œâ”€â”€ .git\
â”‚   â”œâ”€â”€ .autonomous_runs\       # Separate tracking
â”‚   â””â”€â”€ pipeline.py             # Generated code
â”‚
â””â”€â”€ my-api\
    â”œâ”€â”€ .git\
    â”œâ”€â”€ .autonomous_runs\
    â””â”€â”€ src\

c:\dev\Autopack\                # Orchestrator (separate)
â”œâ”€â”€ config\
â”œâ”€â”€ integrations\
â””â”€â”€ src\autopack\
```

**Perfect isolation!** Each project is completely independent.

---

## **Planning a Build (In This Chat!)**

### **Example Conversation:**

**You:** "I want to build a FastAPI service with PostgreSQL database, user authentication, and a REST API for managing tasks"

**Me (Cursor):** Let me check the feature catalog...

I found:
- `fastapi_users` repo - Production-ready auth (12k stars, MIT)
- PostgreSQL with SQLAlchemy - In catalog
- REST API patterns - Build from scratch

**Recommended Plan:**
- **Tier 1:** Setup FastAPI + SQLAlchemy
  - Phase 1.1: Create FastAPI app structure
  - Phase 1.2: Setup PostgreSQL connection
  - Phase 1.3: Create database models

- **Tier 2:** Add Authentication (reuse fastapi_users)
  - Phase 2.1: Install fastapi_users (external_feature_reuse)
  - Phase 2.2: Configure auth endpoints
  - Phase 2.3: Add user registration/login

- **Tier 3:** Task Management API
  - Phase 3.1: Create Task model
  - Phase 3.2: CRUD endpoints for tasks
  - Phase 3.3: Add task filtering/search

**Budget:** ~60% lower than building from scratch (due to fastapi_users reuse)
**Estimated:** ~15,000 tokens, $0.50 total cost

**You:** "Sounds good, go ahead!"

**Me:** Creating run configuration... (generates tiers/phases JSON)

```python
# I'll create this for you
supervisor = Supervisor(target_repo_path="c:\\Projects\\task-manager-api")
result = supervisor.run_autonomous_build(
    run_id="task-manager-v1",
    tiers=[...],  # From the plan above
    phases=[...]
)
```

**Autopack:** Builds it autonomously!

---

## **Advanced: Multiple Projects**

### **Scenario: Building 3 Microservices**

```python
from integrations.supervisor import Supervisor

projects = {
    "user-service": "c:\\Projects\\user-service",
    "order-service": "c:\\Projects\\order-service",
    "payment-service": "c:\\Projects\\payment-service"
}

for project_name, project_path in projects.items():
    supervisor = Supervisor(target_repo_path=project_path)

    # Each has its own plan
    result = supervisor.run_autonomous_build(
        run_id=f"{project_name}-v1",
        tiers=get_tiers_for(project_name),
        phases=get_phases_for(project_name)
    )

    print(f"âœ… {project_name} completed")
```

**Result:** 3 completely isolated microservices, each with its own repo and tracking.

---

## **What About Docker?**

Docker currently mounts `/workspace` to the Autopack directory. For now:

**Option 1:** Run supervisor outside Docker (recommended)
```bash
python examples/multi_project_example.py
```

**Option 2:** Manually mount your project
```yaml
# docker-compose.yml
volumes:
  - c:\Projects\my-app:/workspace
```

**Future:** Dynamic project mounting (coming soon)

---

## **FAQ**

### **Q: Where do I chat to plan my build?**
**A:** Right here in this Cursor chat! Just describe what you want to build and I'll:
1. Check feature catalog for reusable repos
2. Suggest a plan with tiers/phases
3. Estimate cost and timeline
4. Generate the code to run it

### **Q: Can I revise the plan mid-build?**
**A:** Not yet. For now, create a new run with the revised plan. Mid-run plan updates coming soon.

### **Q: Does it stop between tiers for review?**
**A:** No, it runs all tiers/phases continuously. To review between tiers, run one tier at a time.

### **Q: How do I switch projects?**
**A:** Just change `target_repo_path`:
```python
supervisor = Supervisor(target_repo_path="c:\\Projects\\different-project")
```

### **Q: Can projects share code?**
**A:** Not automatically. But you can:
1. Add shared library to feature_catalog.yaml
2. Reference it in multiple project plans
3. Autopack will reuse it with `external_feature_reuse` category

---

## **Next Steps**

1. âœ… **Try the example:**
   ```bash
   python examples/multi_project_example.py
   ```

2. âœ… **Plan your first project (in this chat!):**
   Tell me what you want to build and I'll create the plan.

3. âœ… **Review the results:**
   Check `c:\\Projects\\your-project\\` for generated code.

4. âœ… **Iterate:**
   Run more builds, refine, improve!

---

**You're ready to build multiple isolated projects!** ğŸ‰

Try the example now: `python examples/multi_project_example.py`
