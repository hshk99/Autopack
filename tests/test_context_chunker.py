"""
Tests for context_chunker.py (BUILD-125 Phase E)

Tests file profiling, chunking, and integration with grounded context.
"""

import pytest
from autopack.context_chunker import (
    ContextChunker,
    ChunkRef
)


@pytest.fixture
def tmp_workspace(tmp_path):
    """Create temporary workspace with test files"""
    workspace = tmp_path / "workspace"
    workspace.mkdir()
    return workspace


@pytest.fixture
def chunker(tmp_workspace):
    """Create ContextChunker instance"""
    return ContextChunker(tmp_workspace)


def test_profile_small_file_no_chunking(chunker, tmp_workspace):
    """Small files (<1000 lines) should not be chunked"""
    # Create small Python file
    small_file = tmp_workspace / "small.py"
    small_file.write_text('\n'.join([f"# Line {i}" for i in range(500)]))

    profile = chunker.profile_file("small.py")

    assert profile.line_count == 500
    assert profile.language == "python"
    assert not profile.is_minified
    assert not profile.is_generated
    assert not profile.should_chunk()  # Too small


def test_profile_large_file_should_chunk(chunker, tmp_workspace):
    """Large files (>1000 lines) should be chunked"""
    # Create large Python file with classes
    large_file = tmp_workspace / "large.py"
    content = []
    for i in range(1500):
        content.append(f"# Line {i}")

    large_file.write_text('\n'.join(content))

    profile = chunker.profile_file("large.py")

    assert profile.line_count == 1500
    assert profile.language == "python"
    assert profile.should_chunk()  # Large enough


def test_profile_minified_file(chunker, tmp_workspace):
    """Minified files should not be chunked"""
    # Create minified file (long lines)
    minified_file = tmp_workspace / "bundle.js"
    long_line = "a" * 1000
    content = '\n'.join([long_line] * 10)
    minified_file.write_text(content)

    profile = chunker.profile_file("bundle.js")

    assert profile.is_minified
    assert not profile.should_chunk()  # Minified files skipped


def test_profile_generated_file(chunker, tmp_workspace):
    """Generated files should not be chunked"""
    # Create generated file with marker
    generated_file = tmp_workspace / "proto_pb2.py"
    content = """# AUTO-GENERATED by protobuf compiler
# DO NOT EDIT

class Message:
    pass
"""
    generated_file.write_text(content)

    profile = chunker.profile_file("proto_pb2.py")

    assert profile.is_generated
    assert not profile.should_chunk()  # Generated files skipped


def test_chunk_python_file_with_classes(chunker, tmp_workspace):
    """Python files should be chunked by class/function boundaries"""
    python_file = tmp_workspace / "module.py"
    content = '''"""Module docstring"""

class Foo:
    """Foo class"""
    def method(self):
        pass

class Bar:
    """Bar class"""
    def another_method(self):
        pass

def standalone_function():
    """Standalone function"""
    pass
'''
    # Make it large enough to chunk
    content += '\n'.join([f"# Padding line {i}" for i in range(1000)])
    python_file.write_text(content)

    chunks = chunker.chunk_file("module.py")

    assert len(chunks) >= 3  # At least Foo, Bar, standalone_function

    # Check chunk types
    class_chunks = [c for c in chunks if c.kind == "class"]
    func_chunks = [c for c in chunks if c.kind == "function"]

    assert len(class_chunks) >= 2  # Foo, Bar
    assert len(func_chunks) >= 1  # standalone_function

    # Check docstrings extracted
    foo_chunk = [c for c in class_chunks if c.symbol_name == "Foo"][0]
    assert foo_chunk.docstring == "Foo class"


def test_chunk_python_file_syntax_error(chunker, tmp_workspace):
    """Files with syntax errors fall back to heuristic chunking"""
    bad_python = tmp_workspace / "bad.py"
    content = '''class Foo
    # Missing colon - syntax error
    def method(self):
        pass
'''
    # Make it large enough
    content += '\n'.join([f"# Line {i}" for i in range(1000)])
    bad_python.write_text(content)

    chunks = chunker.chunk_file("bad.py")

    # Should still return chunks via heuristic fallback
    assert len(chunks) > 0


def test_chunk_javascript_file_heuristic(chunker, tmp_workspace):
    """JavaScript files use heuristic chunking"""
    js_file = tmp_workspace / "app.js"
    content = '''class AppController {
    constructor() {
        // ...
    }
}

function handleRequest(req, res) {
    // ...
}

const helper = (data) => {
    // ...
}
'''
    # Make it large enough
    content += '\n'.join([f"// Comment {i}" for i in range(1000)])
    js_file.write_text(content)

    chunks = chunker.chunk_file("app.js")

    assert len(chunks) > 0

    # Check for class chunk
    class_chunks = [c for c in chunks if c.kind == "class"]
    assert len(class_chunks) >= 1

    # Check for function chunks
    func_chunks = [c for c in chunks if c.kind == "function"]
    assert len(func_chunks) >= 1


def test_chunk_limit_enforcement(chunker, tmp_workspace):
    """Files with too many chunks should be limited"""
    from autopack.context_chunker import MAX_CHUNKS_PER_FILE

    # Create file with many small functions
    many_funcs = tmp_workspace / "many.py"
    content = []
    for i in range(MAX_CHUNKS_PER_FILE + 20):
        content.append(f"def func_{i}():")
        content.append("    pass")
        content.append("")

    many_funcs.write_text('\n'.join(content))

    chunks = chunker.chunk_file("many.py")

    # Should be limited to MAX_CHUNKS_PER_FILE
    assert len(chunks) <= MAX_CHUNKS_PER_FILE


def test_chunk_summary_formatting(chunker):
    """Chunk summaries should be formatted correctly"""
    chunks = [
        ChunkRef(
            file_path="test.py",
            start_line=1,
            end_line=10,
            symbol_name="Foo",
            kind="class",
            docstring="Foo class documentation"
        ),
        ChunkRef(
            file_path="test.py",
            start_line=12,
            end_line=20,
            symbol_name="bar",
            kind="function",
            docstring=None
        ),
    ]

    summary = chunker.build_chunk_summary(chunks, max_chars=500)

    assert "class `Foo`" in summary
    assert "lines 1-10" in summary
    assert "Foo class documentation" in summary
    assert "function `bar`" in summary
    assert "lines 12-20" in summary


def test_chunk_summary_truncation(chunker):
    """Large chunk lists should be truncated"""
    # Create many chunks
    chunks = [
        ChunkRef(
            file_path="test.py",
            start_line=i * 10,
            end_line=(i + 1) * 10,
            symbol_name=f"func_{i}",
            kind="function"
        )
        for i in range(100)
    ]

    summary = chunker.build_chunk_summary(chunks, max_chars=200)

    # Should be truncated
    assert "... and" in summary
    assert "more" in summary


def test_language_detection(chunker, tmp_workspace):
    """Language detection from file extensions"""
    test_files = {
        "test.py": "python",
        "app.js": "javascript",
        "component.tsx": "typescript",
        "Main.java": "java",
        "unknown.xyz": "unknown",
    }

    for filename, expected_lang in test_files.items():
        file_path = tmp_workspace / filename
        file_path.write_text("// content")

        profile = chunker.profile_file(filename)
        assert profile.language == expected_lang


def test_stable_chunk_boundaries(chunker, tmp_workspace):
    """Chunk boundaries should be deterministic"""
    python_file = tmp_workspace / "stable.py"
    content = '''class Foo:
    def method1(self):
        pass

class Bar:
    def method2(self):
        pass
'''
    content += '\n'.join([f"# Line {i}" for i in range(1000)])
    python_file.write_text(content)

    # Run chunking twice
    chunks1 = chunker.chunk_file("stable.py")
    chunks2 = chunker.chunk_file("stable.py")

    # Should be identical
    assert len(chunks1) == len(chunks2)
    for c1, c2 in zip(chunks1, chunks2):
        assert c1.start_line == c2.start_line
        assert c1.end_line == c2.end_line
        assert c1.symbol_name == c2.symbol_name
        assert c1.kind == c2.kind
