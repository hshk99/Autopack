# Market Research & Business Analysis Template (RIGOROUS, Universal)

**Purpose**: Provide a rigorous, profit‑focused market research and business analysis for a new product or project.  
**Audience**: Founder / product owner who wants an honest GO/NO‑GO view, clear wedge, and a realistic path to profitability.

The agent using this template should:
- Quantify wherever possible (TAM/SAM/SOM, CAC, LTV, pricing, etc.).
- Be explicitly sceptical about “nice to have” ideas and weak differentiation.
- Focus on finding a narrow, high‑value wedge and 10x outcomes vs the *real* current baseline.
- Optimise for profitability and defensibility, not just “cool product”.

Assume that:
- You will receive a separate document (or prompt context) that describes the **product idea**, its **target users**, and any early thinking.
- You may use the web to gather up‑to‑date data, competitors, and benchmarks.

---

## 0. Executive Summary

Provide a concise overview (max ~400 words):

- **Product one‑liner**: what this product is and who it is for.
- **Primary wedge**: the single most promising initial segment + job‑to‑be‑done.
- **GO/NO‑GO recommendation**: GO / CONDITIONAL GO / NO‑GO.
- **Overall score (1–10)** with a short justification.
- **Top 3 reasons to proceed**.
- **Top 3 reasons to be cautious or stop**.
- High‑level **TAM / SAM** and **rough revenue potential** over 3–5 years.
- One **clear next step** (what the founder should actually do next).

---

## 1. Market Size & Opportunity

### 1.1 Market definition

- Define the **category** this product belongs to (e.g., “vertical SaaS for X”, “developer tool”, “consumer productivity app”).
- State the **core problem** and the **job‑to‑be‑done** in 1–2 sentences.
- Identify whether this is a **replacement**, **augmentation**, or **net‑new** behaviour.

### 1.2 TAM (Total Addressable Market)

- Estimate global TAM in **$ per year** and **number of potential users/customers**.
- Use at least one credible external source per estimate.
- Explain clearly how you derived TAM (top‑down and/or bottom‑up).

### 1.3 SAM (Serviceable Addressable Market)

- Narrow TAM to the portion realistically addressable by:
  - Platform (desktop/mobile/web/region).
  - Customer type (individuals, SMB, mid‑market, enterprise).
  - Any constraints (offline‑first, regulated industries, etc.).
- Estimate SAM in **$ per year** and **number of users/customers**.
- Be explicit about which slices of the market you are *excluding* and why.

### 1.4 SOM (Serviceable Obtainable Market)

- Provide **realistic** Year 1 / Year 3 / Year 5 capture scenarios, not fantasy:
  - Users/customers.
  - Paying users/customers.
  - Annual revenue (range).
- State assumptions for:
  - Conversion rate (free → paid, trial → paid).
  - Average ARPU.
  - Growth drivers (channels, virality, etc.).
- Call out which assumptions are **most fragile**.

---

## 2. Customer Segments & Economics

### 2.1 Segment identification

Identify the main candidate segments (usually 2–4):

For each segment:
- Who they are (role, company size, geography where relevant).
- What core **jobs‑to‑be‑done** they have related to this product.
- What they do today (tools, hacks, manual workflows).
- How painful the problem is (nice‑to‑have vs must‑have).

### 2.2 Economics per segment

For each segment, estimate:

- Approximate **segment size** (users/customers).
- **Willingness to pay** (WTP) per month or per year.
- Likely **retention** (churn, contract length, or typical tenure).
- Plausible **acquisition channels** and corresponding CAC ranges.
- **LTV** estimate and **LTV/CAC** ratio (even rough ranges are fine).

### 2.3 Segment priority matrix

Summarise in a table with (for each segment):

- Size (S).
- Pain intensity (P).
- WTP / ARPU (A).
- CAC difficulty (C).
- Switching cost (SC).
- LTV/CAC (LC).
- Overall **priority** (High / Medium / Low).

Explicitly recommend:

- **Primary wedge segment** (the one to focus on first).
- **Secondary segments** (that might be addressed later).
- Short justification: choose high‑pain, high‑LTV/CAC segments over simply “largest”.

---

## 3. Competitive Landscape

### 3.1 Types of alternatives

Identify and briefly describe:

- **Direct competitors** (same job, same user).
- **Indirect / partial substitutes** (solve the job in a different way).
- **Do‑nothing / manual workflows** (status quo).

### 3.2 Key competitors (top 5–10)

For each major competitor:

- Target segment(s).
- Core value proposition.
- Key features.
- Pricing model and rough price points.
- Distribution strengths (brand, ecosystem, marketplace, etc.).
- Evidence of traction if available (funding, customers, reviews).

### 3.3 Gaps & opportunities

- Where are competitors **strong**? (especially along workflows, integrations, network effects).
- Where are they **weak**? (price, complexity, coverage gaps, UX, privacy, platform gaps, regions, languages, etc.).
- Summarise 3–5 **concrete opportunities** where a new product could be meaningfully better, not just different.

---

## 4. Switching Costs & Adoption

For the top 2–3 alternatives (including “do nothing”) that users are most likely to stick with:

### 4.1 Current baseline

Describe how users in each high‑priority segment **actually** work today:

- Tools they use.
- Time they spend.
- Typical costs (money, time, cognitive load, errors).

### 4.2 Switching cost analysis

For each alternative, analyse:

- **Set‑up / migration effort** (hours, skills needed).
- **Learning curve** (how hard it is to adopt a new product here).
- **Monetary lock‑in** (multi‑year contracts, sunk costs).
- **Data lock‑in** (hard to export, proprietary formats).
- **Political / emotional lock‑in** (stakeholder buy‑in, risk aversion).

Provide a rough **barrier level**: Low / Medium / High, and what that implies for adoption.

### 4.3 “What we must offer to win”

For each high‑priority segment, clearly state:

- What would make switching **obviously worthwhile**? (e.g., “cuts this workflow from 10 hours to 2 hours”, “saves $X/month”, “removes specific high‑stress risk”).  
- Which aspects must be **strictly better**, and which can be “good enough”.

---

## 5. 10x Differentiation & Wedge

### 5.1 Baseline vs 10x

For the **primary wedge segment**:

- Describe the **baseline workflow** in detail (time, cost, error risk, complexity).
- Articulate what “10x better” would *actually mean* here, in measurable terms:
  - Time reduction.
  - Cost reduction.
  - Risk reduction.
  - Outcome quality (accuracy, compliance, reliability).
  - Cognitive load / peace of mind.

Be honest if the product idea is only 2–3x better and say so.

### 5.2 Differentiation axes

List the main dimensions where this product **could** differentiate:

- Outcome (e.g., time to complete high‑value job).
- UX & simplicity (esp. for non‑technical users).
- Price / value.
- Privacy / security / compliance.
- Platform reach (cross‑platform, offline, edge use cases).
- Personalisation, automation, or “opinionated workflows”.

Highlight at most **3–5 key differentiation axes** that matter to real users and can’t be trivially matched.

### 5.3 Wedge thesis

Propose a concrete wedge thesis of the form:

> “For [primary segment] doing [critical job], this product will [measured outcome], by [specific approach]. We will not try to be everything to everyone in v1.”

Explain how this wedge can later broaden to other segments or use‑cases without diluting focus.

---

## 6. Moat & Defensibility

Evaluate how defensible success would be if the product works:

- **Technology**: Is there real technical difficulty, or can competitors replicate in 6–24 months?  
- **Data**: Are there opportunities for a data advantage (proprietary labels, user behaviour, performance logs) that can ethically be built over time?  
- **Network effects / ecosystem**: Any sharing, marketplace, or integration dynamics that get stronger with scale?  
- **Distribution / brand**: Any way to own a niche (e.g., “best tool for X profession”) that gives a durable advantage?  
- **Regulation / compliance**: Any required certifications or approvals that are hard for followers to obtain?

Be explicit if the moat is **weak** and success will mainly depend on speed, UX, and brand rather than deep defensibility.

---

## 7. Pricing & Packaging

Based on segment economics and competitor pricing, propose a **multi‑tier structure** (if applicable), such as:

- **Free / starter**:
  - Who it serves.
  - Clear usage limits and feature limits (restrain high‑cost features).
  - Goal: product discovery and light use, not full value extraction.

- **Core / Pro (individuals or small teams)**:
  - Target ARPU and billing model (monthly/annual, per‑seat, usage‑based, etc.).
  - Feature set and usage caps that justify the price.

- **Business / Premium (higher‑ARPU segment)**:
  - Extra capabilities aligned to high‑WTP users (compliance, collaboration, advanced workflows, better SLAs, higher limits, etc.).

- **Enterprise / Custom (optional)**:
  - If relevant, outline what would be included (SSO, custom deployments, integrations, etc.).

Also:

- Recommend **indicative price points** and annual discounts.
- Check that proposed pricing aligns with segment WTP and competitor benchmarks.
- Explain how pricing protects **gross margin** where 3rd‑party APIs (LLMs, OCR, infra) are used.

---

## 8. Financial Model & Unit Economics

### 8.1 Unit economics

Using your earlier segment analysis, estimate:

- Blended **CAC** (by weighted average across segments or go‑to‑market motions).
- Blended **LTV**.
- **LTV/CAC ratio**.
- **Payback period** (months to recoup CAC).

Highlight if any numbers rely on aggressive assumptions (e.g., very low churn, very cheap CAC).

### 8.2 3–5 year revenue scenarios

Provide **at least two scenarios** (Base and Upside; optional Downside), showing for each year:

- MAUs / paying customers.
- ARPU assumptions.
- Annual revenue.
- Very simple cost structure assumptions (infra, APIs, team, marketing), and whether the business could become profitable.

Explain:

- What must happen for the Base case to be achieved.
- What extra must happen for the Upside case.
- Which levers most affect the outcome (conversion, churn, ACV, CAC, etc.).

---

## 9. Technical & Execution Feasibility

### 9.1 Technical feasibility

- Identify any **hard technical problems** (e.g., accuracy targets, latency constraints, offline requirements, non‑trivial integrations).
- Note dependencies on **3rd‑party APIs or platforms** that could affect costs or stability.
- Call out any **regulatory / safety constraints** (e.g., medical, financial, legal).

### 9.2 Execution feasibility

- Estimate rough **build complexity** (simple / moderate / complex) for an experienced small team.
- Identify which parts of the product are **critical path** for an MVP.
- Note any **skills** that are must‑have (e.g., ML engineering, devops, regulatory expertise).

---

## 10. Risk Matrix & Pivot Options

List the **top 10 risks** with:

- **Description**.
- **Likelihood (1–10)**.
- **Impact (1–10)** on the business if it happens.
- **Priority score** = L × I.
- Short **mitigation ideas**.

Pay special attention to:

- Failure to achieve 10x value vs the real baseline.
- Underestimating CAC or overestimating retention.
- Weak moat and fast copycats.
- Technical under‑delivery on core outcomes.
- Regulatory / compliance surprises (if relevant).

Also suggest **pivot options** if the original thesis fails, e.g.:

- Narrowing to a higher‑ARPU niche.
- Repositioning the product as an internal tool, plugin, or API.
- Changing from local‑first to cloud‑first, or vice versa.

---

## 11. Feature Opportunities & Roadmap Thesis

This section should **not** be an endless feature wishlist. Focus on structured, high‑leverage ideas.

### 11.1 Foundation vs differentiation

For the primary wedge segment:

- **Foundation features**:
  - The minimum feature set needed to credibly solve the core job better than the baseline.
  - These should support a thin, end‑to‑end workflow.

- **Differentiating features**:
  - Features that transform the product from “useful tool” into “personal operations layer” for this job.
  - Think in categories such as:
    - Deep customisation of workflows/behaviour.
    - Smart automation with strong safety/rollback.
    - Domain‑specific “packs” or workflows for common scenarios.
    - Summaries, explanations, and insights that users would otherwise not have.

### 11.2 Domain‑specific “packs” and workflows

Translate the “pack” pattern generically:

- Identify recurring, high‑stakes scenarios in this domain (e.g., audits, submissions, applications, launches, onboarding campaigns, etc.).
- For 2–3 of the most important scenarios, outline:
  - What inputs users have today (documents, data, assets).
  - What outputs they need (reports, submissions, decks, configs).
  - How the product could:
    - Cluster and structure inputs.
    - Check them against a schema or checklist.
    - Produce a high‑quality final output (bundle, report, deck, etc.).

Do not hard‑code domain examples; always adapt to the current product’s domain when running this template.

### 11.3 Data & telemetry strategy

Given the product’s domain and sensitivity of data:

- Propose a **default‑safe telemetry layer**:
  - Usage analytics that do *not* include user content (events, feature usage, performance).
- Consider optional, **explicit opt‑in** programmes if content‑level data could significantly improve the product:
  - What would be collected.
  - How it would be anonymised / protected.
  - How users would benefit.
- Highlight any **regulatory or trust constraints** (GDPR, HIPAA, etc.).
- Explain whether and how a **modest data advantage** could be built over time without undermining the product’s positioning.

### 11.4 Phasing (MVP → v1 → v2)

Propose a **layered roadmap**:

- **MVP (first 6–9 months)**:
  - Thin, end‑to‑end flow for the primary wedge job.
  - Only essential foundation features and minimal differentiation.

- **v1.1 / v1.2**:
  - Add 2–4 high‑leverage differentiating features proven by early user feedback.

- **v2+**:
  - Richer packs/workflows, more automation, and optional expansion to secondary segments.

Keep the MVP narrow and realistic; do not overload it.

---

## 12. Final GO/NO‑GO & Next Steps

### 12.1 Scores

Provide scores (1–10) for:

- Market opportunity.
- Competitive position.
- Financial viability.
- Technical & execution feasibility.

Show the simple average and interpret it (e.g., 6.5/10 = Conditional GO).

### 12.2 Recommendation

State one of:

- **GO** – build this, with clear strategic guardrails.
- **CONDITIONAL GO** – worth pursuing *if* the founder accepts explicit risks and constraints.
- **NO‑GO** – not worth building as described; briefly say why.

Be direct and founder‑honest. Avoid vague language.

### 12.3 Top 3 strategic imperatives

If GO or CONDITIONAL GO, list the **three most important imperatives**, usually along the lines of:

- Nail the 10x outcome for the primary wedge.
- Prioritise the right segment based on LTV/CAC and pain, not headcount.
- Keep v1 ruthlessly small and end‑to‑end, and execute fast before copycats.

### 12.4 Concrete next 90‑day actions

List 5–10 specific actions the founder should take in the next ~90 days, such as:

- Talk to N users from the primary segment to validate X.
- Build a scrappy prototype of the core workflow.
- Run a small beta and measure a specific time‑savings or outcome metric.
- Validate acquisition channel assumptions through small experiments.

Keep these actions practical and grounded in the analysis above.
