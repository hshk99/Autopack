"""Google Gemini Builder and Auditor implementations

Uses the Google Generative AI Python SDK for Gemini models.

Environment variables:
- GOOGLE_API_KEY: API key for Google Gemini
"""

import os
import json
import logging
from typing import Dict, List, Optional

try:
    import google.generativeai as genai
    GENAI_AVAILABLE = True
except ImportError:
    GENAI_AVAILABLE = False
    genai = None

from .llm_client import BuilderResult, AuditorResult

logger = logging.getLogger(__name__)


def get_gemini_client():
    """Configure and return Gemini API client.

    Returns:
        True if configured successfully, False otherwise
    """
    api_key = os.getenv("GOOGLE_API_KEY")
    if not api_key:
        return False

    if not GENAI_AVAILABLE:
        return False

    genai.configure(api_key=api_key)
    return True


class GeminiBuilderClient:
    """Builder implementation using Google Gemini API

    Generates code patches from phase specifications.
    Uses Gemini 2.5 Pro for code generation.
    """

    def __init__(self, api_key: Optional[str] = None):
        """Initialize Gemini client

        Args:
            api_key: Google API key (defaults to GOOGLE_API_KEY env var)
        """
        if not GENAI_AVAILABLE:
            raise ImportError("google-generativeai package is required for Gemini client. Install with: pip install google-generativeai")

        self.api_key = api_key or os.getenv("GOOGLE_API_KEY")

        if not self.api_key:
            raise ValueError("GOOGLE_API_KEY environment variable is required for Gemini client")

        genai.configure(api_key=self.api_key)

    def execute_phase(
        self,
        phase_spec: Dict,
        file_context: Optional[Dict] = None,
        max_tokens: Optional[int] = None,
        model: str = "gemini-2.5-pro",
        project_rules: Optional[List] = None,
        run_hints: Optional[List] = None
    ) -> BuilderResult:
        """Execute a phase and generate code patch

        Args:
            phase_spec: Phase specification with fields:
                - phase_id: str
                - task_category: str
                - complexity: str
                - description: str
                - acceptance_criteria: List[str]
            file_context: Current repo files (optional, for context)
            max_tokens: Token budget limit for this call
            model: Gemini model to use
            project_rules: Persistent project learned rules (Stage 0B)
            run_hints: Within-run hints from earlier phases (Stage 0A)

        Returns:
            BuilderResult with patch_content and metadata
        """
        try:
            # Build system prompt for Builder
            system_prompt = self._build_system_prompt()

            # Build user prompt with phase details
            user_prompt = self._build_user_prompt(
                phase_spec, file_context, project_rules, run_hints
            )

            # Create model instance
            gemini_model = genai.GenerativeModel(
                model_name=model,
                system_instruction=system_prompt,
                generation_config=genai.GenerationConfig(
                    max_output_tokens=max_tokens or 16384,
                    temperature=0.2
                )
            )

            # Call Gemini API
            response = gemini_model.generate_content(user_prompt)

            # Extract content
            content = response.text

            # Extract tokens used (Gemini provides usage metadata)
            tokens_used = 0
            if hasattr(response, 'usage_metadata'):
                tokens_used = (
                    getattr(response.usage_metadata, 'prompt_token_count', 0) +
                    getattr(response.usage_metadata, 'candidates_token_count', 0)
                )

            # Extract patch from raw text
            patch_content = self._extract_diff_from_text(content)

            if not patch_content:
                logger.warning("No git diff markers found in response, using raw content")
                patch_content = content

            logger.debug(f"Gemini Builder completed: {tokens_used} tokens, patch length: {len(patch_content)}")

            return BuilderResult(
                success=True,
                patch_content=patch_content,
                builder_messages=["Generated by Gemini Builder"],
                tokens_used=tokens_used,
                model_used=model
            )

        except Exception as e:
            logger.error(f"Gemini Builder execution failed: {str(e)}")
            return BuilderResult(
                success=False,
                patch_content="",
                builder_messages=[f"Gemini Builder error: {str(e)}"],
                tokens_used=0,
                model_used=model,
                error=str(e)
            )

    def _extract_diff_from_text(self, text: str) -> str:
        """Extract git diff content from text that may contain explanations."""
        lines = text.split('\n')
        diff_lines = []
        in_diff = False

        for line in lines:
            if line.startswith('diff --git'):
                in_diff = True
                diff_lines.append(line)
            elif in_diff:
                if (line.startswith(('index ', '---', '+++', '@@', '+', '-', ' ')) or
                    line.startswith('new file mode') or
                    line.startswith('deleted file mode') or
                    line.startswith('similarity index') or
                    line.startswith('rename from') or
                    line.startswith('rename to') or
                    line == ''):
                    diff_lines.append(line)
                elif line.startswith('diff --git'):
                    diff_lines.append(line)
                else:
                    if line.startswith('```') or line.startswith('#'):
                        break

        return '\n'.join(diff_lines) if diff_lines else ""

    def _build_system_prompt(self) -> str:
        """Build system prompt for Builder"""
        return """You are an expert software engineer working as the Builder in an autonomous build system.

Your role:
1. Read the phase specification carefully
2. Generate clean, working code that implements the requirements
3. Return a unified git diff/patch format
4. Ensure code follows best practices and is production-ready

CRITICAL REQUIREMENTS:
1. Output ONLY a raw git diff format patch
2. Do NOT wrap it in JSON, markdown code blocks, or any other format
3. Do NOT add explanatory text before or after the patch
4. Start directly with: diff --git a/path/to/file.py b/path/to/file.py
5. NEVER use "..." or any abbreviation - show COMPLETE code
6. NEVER truncate or abbreviate ANY part of the diff
7. Show the ENTIRE file content - do NOT use ellipsis (...) ANYWHERE

GIT DIFF FORMAT RULES:
- Each file change MUST start with: diff --git a/PATH b/PATH
- Followed by: index HASH..HASH
- Then: --- a/PATH and +++ b/PATH
- Then: @@ -LINE,COUNT +LINE,COUNT @@ CONTEXT
- Then the actual changes with +/- prefixes
- Use COMPLETE file paths from repository root
- Do NOT use relative or partial paths
- Do NOT abbreviate variable names, function names, or ANY code

Guidelines:
- Write idiomatic code for the language/framework
- Include error handling where appropriate
- Add docstrings/comments for complex logic
- Follow existing code style in the repository
- Don't over-engineer - keep it simple and focused
- Output ONLY the raw git diff format patch"""

    def _build_user_prompt(
        self,
        phase_spec: Dict,
        file_context: Optional[Dict],
        project_rules: Optional[List] = None,
        run_hints: Optional[List] = None
    ) -> str:
        """Build user prompt with phase details"""
        prompt_parts = []

        # Stage 0A + 0B: Inject learned rules and hints
        if project_rules or run_hints:
            from .learned_rules import format_rules_for_prompt, format_hints_for_prompt

            if project_rules:
                rules_section = format_rules_for_prompt(project_rules)
                if rules_section:
                    prompt_parts.append(rules_section)
                    prompt_parts.append("\n")

            if run_hints:
                hints_section = format_hints_for_prompt(run_hints)
                if hints_section:
                    prompt_parts.append(hints_section)
                    prompt_parts.append("\n")

        # Add phase details
        prompt_parts.append(f"## Phase Specification\n")
        prompt_parts.append(f"**Phase ID:** {phase_spec.get('phase_id')}\n")
        prompt_parts.append(f"**Task Category:** {phase_spec.get('task_category')}\n")
        prompt_parts.append(f"**Complexity:** {phase_spec.get('complexity')}\n")
        prompt_parts.append(f"**Description:** {phase_spec.get('description')}\n")

        if acceptance_criteria := phase_spec.get('acceptance_criteria'):
            prompt_parts.append(f"\n**Acceptance Criteria:**\n")
            for idx, criterion in enumerate(acceptance_criteria, 1):
                prompt_parts.append(f"{idx}. {criterion}\n")

        if file_context:
            prompt_parts.append(f"\n## Repository Context\n")
            if existing_files := file_context.get('existing_files'):
                prompt_parts.append(f"**Existing Files:**\n")
                for file_path, content in existing_files.items():
                    prompt_parts.append(f"\n### {file_path}\n```\n{content}\n```\n")

        prompt_parts.append(f"\n## Instructions\n")
        prompt_parts.append("Generate a complete implementation as a unified git diff/patch.")

        return "\n".join(prompt_parts)


class GeminiAuditorClient:
    """Auditor implementation using Google Gemini API

    Reviews code patches and finds issues.
    Uses Gemini 2.5 Pro for code review and analysis.
    """

    def __init__(self, api_key: Optional[str] = None):
        """Initialize Gemini client

        Args:
            api_key: Google API key (defaults to GOOGLE_API_KEY env var)
        """
        if not GENAI_AVAILABLE:
            raise ImportError("google-generativeai package is required for Gemini client. Install with: pip install google-generativeai")

        self.api_key = api_key or os.getenv("GOOGLE_API_KEY")

        if not self.api_key:
            raise ValueError("GOOGLE_API_KEY environment variable is required for Gemini client")

        genai.configure(api_key=self.api_key)

    def review_patch(
        self,
        patch_content: str,
        phase_spec: Dict,
        max_tokens: Optional[int] = None,
        model: str = "gemini-2.5-pro",
        project_rules: Optional[List] = None,
        run_hints: Optional[List] = None
    ) -> AuditorResult:
        """Review a patch and find issues

        Args:
            patch_content: Git diff/patch to review
            phase_spec: Phase specification for context
            max_tokens: Token budget limit for this call
            model: Gemini model to use
            project_rules: Persistent project learned rules (Stage 0B)
            run_hints: Within-run hints from earlier phases (Stage 0A)

        Returns:
            AuditorResult with issues_found and metadata
        """
        try:
            system_prompt = self._build_system_prompt()
            user_prompt = self._build_user_prompt(
                patch_content, phase_spec, project_rules, run_hints
            )

            # Create model instance with JSON mode
            gemini_model = genai.GenerativeModel(
                model_name=model,
                system_instruction=system_prompt,
                generation_config=genai.GenerationConfig(
                    max_output_tokens=max_tokens or 4096,
                    temperature=0.1,
                    response_mime_type="application/json"
                )
            )

            # Call Gemini API
            response = gemini_model.generate_content(user_prompt)

            # Parse JSON response
            result_json = json.loads(response.text)

            # Extract tokens used
            tokens_used = 0
            if hasattr(response, 'usage_metadata'):
                tokens_used = (
                    getattr(response.usage_metadata, 'prompt_token_count', 0) +
                    getattr(response.usage_metadata, 'candidates_token_count', 0)
                )

            issues = result_json.get("issues", [])
            has_major_issues = any(
                issue.get("severity") == "major" for issue in issues
            )
            approved = not has_major_issues

            return AuditorResult(
                approved=approved,
                issues_found=issues,
                auditor_messages=result_json.get("messages", []),
                tokens_used=tokens_used,
                model_used=model
            )

        except Exception as e:
            return AuditorResult(
                approved=False,
                issues_found=[{
                    "severity": "major",
                    "category": "auditor_error",
                    "description": f"Gemini Auditor error: {str(e)}",
                    "location": "unknown"
                }],
                auditor_messages=[f"Gemini Auditor error: {str(e)}"],
                tokens_used=0,
                model_used=model,
                error=str(e)
            )

    def _build_system_prompt(self) -> str:
        """Build system prompt for Auditor"""
        return """You are an expert code reviewer working as the Auditor in an autonomous build system.

Your role:
1. Review code patches for issues
2. Check for security vulnerabilities, bugs, code quality problems
3. Classify issues by severity (minor/major)
4. Approve patches with no major issues

Output format (JSON):
{
  "approved": true/false,
  "issues": [
    {
      "severity": "minor|major",
      "category": "security|bug|quality|style|test|documentation",
      "description": "Clear description of the issue",
      "location": "file:line or general area",
      "suggestion": "How to fix (optional)"
    }
  ],
  "messages": ["list of review comments"],
  "tests_verified": true/false
}

Severity guidelines:
- **major**: Security vulnerabilities, critical bugs, missing error handling, broken functionality
- **minor**: Style issues, minor improvements, missing comments, test coverage gaps

Be thorough but fair. Approve patches that work correctly even if they have minor style issues."""

    def _build_user_prompt(
        self,
        patch_content: str,
        phase_spec: Dict,
        project_rules: Optional[List] = None,
        run_hints: Optional[List] = None
    ) -> str:
        """Build user prompt with patch and context"""
        prompt_parts = []

        if project_rules or run_hints:
            from .learned_rules import format_rules_for_prompt, format_hints_for_prompt

            if project_rules:
                rules_section = format_rules_for_prompt(project_rules)
                if rules_section:
                    prompt_parts.append(rules_section)
                    prompt_parts.append("\n")

            if run_hints:
                hints_section = format_hints_for_prompt(run_hints)
                if hints_section:
                    prompt_parts.append(hints_section)
                    prompt_parts.append("\n")

        prompt_parts.append(f"## Phase Context\n")
        prompt_parts.append(f"**Task Category:** {phase_spec.get('task_category')}\n")
        prompt_parts.append(f"**Complexity:** {phase_spec.get('complexity')}\n")
        prompt_parts.append(f"**Description:** {phase_spec.get('description')}\n")

        prompt_parts.append(f"\n## Patch to Review\n```diff\n{patch_content}\n```\n")

        prompt_parts.append(f"\n## Review Instructions\n")
        prompt_parts.append("Review this patch carefully for:")
        prompt_parts.append("1. Security vulnerabilities (SQL injection, XSS, etc.)")
        prompt_parts.append("2. Bugs and logic errors")
        prompt_parts.append("3. Code quality and best practices")
        prompt_parts.append("4. Test coverage (if this is a test phase)")
        prompt_parts.append("5. Documentation clarity (if this is a docs phase)")
        prompt_parts.append("\nReturn your review in the specified JSON format.")

        return "\n".join(prompt_parts)
