# LLM Pricing Configuration
# Updated: 2025-12-01
# Prices in USD per 1,000 tokens

# GLM (Zhipu AI) pricing - LOW COMPLEXITY PROVIDER
# Source: https://open.bigmodel.cn/pricing (GLM-4 Plus)
# Environment: GLM_API_KEY, GLM_API_BASE (optional, defaults to https://open.bigmodel.cn/api/paas/v4)
zhipu:
  "glm-4-plus":
    input_per_1k: 0.0007    # $0.70 per 1M tokens (50 RMB/1M tokens)
    output_per_1k: 0.0007   # $0.70 per 1M tokens (50 RMB/1M tokens)

  # GLM-4.6 model ID
  "glm-4.6-20250101":
    input_per_1k: 0.0007    # $0.70 per 1M tokens
    output_per_1k: 0.0007   # $0.70 per 1M tokens

# Anthropic Claude pricing (as of 2025)
# Source: https://www.anthropic.com/pricing
# Environment: ANTHROPIC_API_KEY
anthropic:
  "claude-opus-4-5":
    input_per_1k: 0.015     # $15.00 per 1M tokens
    output_per_1k: 0.075    # $75.00 per 1M tokens

  "claude-sonnet-4-5":
    input_per_1k: 0.003     # $3.00 per 1M tokens
    output_per_1k: 0.015    # $15.00 per 1M tokens

  "claude-3-opus-20240229":
    input_per_1k: 0.015     # $15.00 per 1M tokens
    output_per_1k: 0.075    # $75.00 per 1M tokens

  "claude-3-sonnet-20240229":
    input_per_1k: 0.003     # $3.00 per 1M tokens
    output_per_1k: 0.015    # $15.00 per 1M tokens

  "claude-3-haiku-20240307":
    input_per_1k: 0.00025   # $0.25 per 1M tokens
    output_per_1k: 0.00125  # $1.25 per 1M tokens

# OpenAI pricing (as of 2025) - FALLBACK PROVIDER
# Source: https://openai.com/api/pricing/
# Environment: OPENAI_API_KEY
# Note: gpt-4o and gpt-4o-mini replaced by GLM as primary cheap model
openai:
  "gpt-5":
    input_per_1k: 0.01      # $10.00 per 1M tokens (estimated)
    output_per_1k: 0.03     # $30.00 per 1M tokens (estimated)

  "gpt-4.5":
    input_per_1k: 0.075     # $75.00 per 1M tokens
    output_per_1k: 0.15     # $150.00 per 1M tokens

  "gpt-4-turbo-2024-04-09":
    input_per_1k: 0.01      # $10.00 per 1M tokens
    output_per_1k: 0.03     # $30.00 per 1M tokens

  # Legacy models (kept for reference, not actively used)
  "gpt-4o":
    input_per_1k: 0.0025    # $2.50 per 1M tokens
    output_per_1k: 0.01     # $10.00 per 1M tokens

  "gpt-4o-mini":
    input_per_1k: 0.00015   # $0.150 per 1M tokens
    output_per_1k: 0.0006   # $0.600 per 1M tokens

  "gpt-3.5-turbo":
    input_per_1k: 0.0005
    output_per_1k: 0.0015

# Google Gemini pricing - MEDIUM COMPLEXITY PROVIDER
# Source: https://ai.google.dev/pricing
# Environment: GOOGLE_API_KEY
google:
  "gemini-2.5-pro":
    input_per_1k: 0.00125   # $1.25 per 1M tokens
    output_per_1k: 0.005    # $5.00 per 1M tokens

  "gemini-2.5-flash":
    input_per_1k: 0.00035   # $0.35 per 1M tokens
    output_per_1k: 0.00105  # $1.05 per 1M tokens

  "gemini-2.5-flash-lite":
    input_per_1k: 0.000075  # $0.075 per 1M tokens
    output_per_1k: 0.0003   # $0.30 per 1M tokens

# Cost calculation helpers
cost_calculation:
  # How to calculate total cost for a call
  # total_cost = (input_tokens * input_per_1k / 1000) + (output_tokens * output_per_1k / 1000)

  # Track costs at multiple levels
  track_at_levels:
    - phase    # Cost per phase
    - tier     # Cost per tier
    - run      # Cost per run
    - project  # Cost across all runs (project backlog)

# Budget enforcement
budgets:
  # Maximum cost per run (optional, in addition to token cap)
  run_cost_cap_usd: null  # Set to dollar amount to enable, e.g., 50.0

  # Alert thresholds (percentage of budget used)
  cost_warning_threshold: 0.75  # Warn at 75% of budget
  cost_critical_threshold: 0.90  # Critical alert at 90%

# Cost optimization strategies
optimization:
  # Use cheaper models for retries after initial failure
  use_cheaper_model_on_retry: false

  # Cache common prompts (if LLM provider supports it)
  enable_prompt_caching: false

  # Batch multiple small operations when possible
  enable_batching: false

# Reporting
reporting:
  # Include cost breakdown in run summaries
  include_cost_in_summaries: true

  # Cost metrics to track
  metrics:
    - total_cost_usd
    - cost_per_phase_avg
    - cost_by_task_category
    - cost_by_model
    - builder_cost_vs_auditor_cost
    - cost_per_successful_phase
    - cost_per_failed_phase

# Example cost calculations for reference (current model stack):
#
# Low complexity phase (glm-4-plus / glm-4.6-20250101):
#   - Builder: 2000 input + 1000 output = $0.0021 (3*0.0007)
#   - Auditor: 1500 input + 500 output = $0.0014 (2*0.0007)
#   - Total: ~$0.0035 per phase
#
# Medium complexity phase (gemini-2.5-pro):
#   - Builder: 5000 input + 3000 output = $0.0213 (5*0.00125 + 3*0.005)
#   - Auditor: 3000 input + 1000 output = $0.0088 (3*0.00125 + 1*0.005)
#   - Total: ~$0.03 per phase
#
# High complexity phase (claude-sonnet-4-5):
#   - Builder: 10000 input + 5000 output = $0.105 (10*0.003 + 5*0.015)
#   - Auditor: 8000 input + 2000 output = $0.054 (8*0.003 + 2*0.015)
#   - Total: ~$0.16 per phase
#
# Estimated run cost (25 phases, mixed complexity):
#   - 5 low + 15 medium + 5 high
#   - ~$0.018 + $0.45 + $0.80 = ~$1.27 per run
#
# Model stack summary:
#   - Low: GLM-4 Plus (Zhipu AI) - cheapest, good for simple tasks
#   - Medium: Gemini 2.5 Pro (Google) - balanced cost/quality
#   - High: Claude Sonnet 4.5 (Anthropic) - premium quality
#   - Escalation: GPT-5 (OpenAI), Claude Opus 4.5 - for critical/failing phases
